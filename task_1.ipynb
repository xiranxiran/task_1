{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  NaiveBayes \"by hand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tag                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from IPython.display import Image\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection.csv',sep=\"\\t\", names=['tag','text'],header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[freemsg, hey, darl, 3, week, word, back, id, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag                                               text\n",
       "0    0  [go, jurong, point, crazi, avail, bugi, n, gre...\n",
       "1    0                       [ok, lar, joke, wif, u, oni]\n",
       "2    1  [free, entri, 2, wkli, comp, win, fa, cup, fin...\n",
       "3    0      [u, dun, say, earli, hor, u, c, alreadi, say]\n",
       "4    0  [nah, dont, think, goe, usf, live, around, tho...\n",
       "5    1  [freemsg, hey, darl, 3, week, word, back, id, ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer() \n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split(r'\\s+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: clean_text(x))\n",
    "data.replace('ham', 0, inplace=True)\n",
    "data.replace('spam', 1,inplace=True)\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pam and spam: \n",
      " 0    4825\n",
      "1     747\n",
      "Name: tag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#overview data\n",
    "print('pam and spam: \\n', (data['tag']).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2786,), (2786,)]\n",
      "[(5572,), (5572,)]\n"
     ]
    }
   ],
   "source": [
    "#split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=data['text']\n",
    "y=data['tag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "print([np.shape(X_train), np.shape(y_train)])\n",
    "print([np.shape(X), np.shape(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for test\n",
    "#print(trainX[0])\n",
    "#print(sum(trainX[0]))\n",
    "#print(len(trainX[0]))\n",
    "#print(len(trainX))\n",
    "type(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a vacabulary list (with unique words): get all the words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.创建一个词表\n",
    "\n",
    "def createVocabList(dataSet):\n",
    "    vocabSet = set()    #创建一个空集\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document)  #创建两个集合的并集\n",
    "    return  list(vocabSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check whether test words in uniqure vacabulary list: vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.遍历查看该单词是否出现，出现该单词则将该单词置1\n",
    "\n",
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    returnVec = [0] * len(vocabList) #Vectorize\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1    #索引位置\n",
    "        else:\n",
    "            print(\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return returnVec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Define bayes training function and classify text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.after Vectorization, define bayes training function\n",
    "\n",
    "def trainNB1(trainX, trainy):\n",
    "    numTrainDocs = len(trainX)\n",
    "    numWords = len(trainX[0])   # total words number\n",
    "    porb_spam = sum(trainy) / float(numTrainDocs)  # probability_spam = total number of spam email / total number of email 侮辱性文件的个数 / 文件总数 = 侮辱性文件出现的概率\n",
    "    \n",
    "    p0Num = np.ones(numWords)  #initialize\n",
    "    p1Num = np.ones(numWords)\n",
    "\n",
    "    p0Denom = 1.0  #initialize denominator\n",
    "    p1Denom = 1.0\n",
    "    \n",
    "    for i in range(numTrainDocs):\n",
    "        if trainy[i] == 1:\n",
    "            p1Num += trainX[i] #calculate total number of words in spam emails in trainX 统计侮辱类别所有的文档中的词的数量\n",
    "            p1Denom += sum(trainX[i])#total number spam words 侮辱类的总单词数量\n",
    "        else:\n",
    "            p0Num += trainX[i]\n",
    "            p0Denom += sum(trainX[i])\n",
    "        \n",
    "    p1Vect = log(p1Num / p1Denom)  #对结果求对数，是为了防止下溢出 \n",
    "    p0Vect = log(p0Num / p0Denom)\n",
    "    \n",
    "    return p0Vect,p1Vect,porb_spam\n",
    "\n",
    "#p0Vec=p0Num/p0Demon是用向量除以词项的总和，我们可以理解成将这个向量标准化，归一化，便于后续的处理\n",
    "\n",
    "# 4. classify\n",
    "\n",
    "def classifyNB(vec2Classify,p0Vec,p1Vec,pClass1):\n",
    "    p1=sum(vec2Classify*p1Vec)+log(pClass1)\n",
    "    p0=sum(vec2Classify*p0Vec)+log(1-pClass1)\n",
    "    if p1>p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    returnVec = [0] * len(vocabList) #Vectorize\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1    #索引位置\n",
    "            \n",
    "#        else:\n",
    "#            print(\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return returnVec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>8185</th>\n",
       "      <th>8186</th>\n",
       "      <th>8187</th>\n",
       "      <th>8188</th>\n",
       "      <th>8189</th>\n",
       "      <th>8190</th>\n",
       "      <th>8191</th>\n",
       "      <th>8192</th>\n",
       "      <th>8193</th>\n",
       "      <th>8194</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 8195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  8185  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   8186  8187  8188  8189  8190  8191  8192  8193  8194  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[1 rows x 8195 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = setOfWords2Vec(myVocabList_all,X_train[5])\n",
    "return_vector = pd.DataFrame(vector).transpose()\n",
    "return_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  NOTE : In terms of the cell below, I didn't use this def testingNB as there are some problems with the loop. ( I'll correct it later. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testingNB():\n",
    "    listPosts,listClasses= X,y\n",
    "    myVocabList=createVocabList(listPosts)\n",
    "    trainMat=[]\n",
    "    for postinDoc in listPosts:\n",
    "        trainMat.append(setOfWords2Vec(myVocabList,postinDoc))\n",
    "    p0V,p1V,pAb=trainNB1(trainMat,listClasses)\n",
    "    testEntry= X_train[5]\n",
    "    thisDoc=setOfWords2Vec(myVocabList,testEntry)\n",
    "    print(testEntry,'classified as:',classifyNB(thisDoc,p0V,p1V,pAb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Testing NB - result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freemsg hey darl 3 week word back id like fun still tb ok xxx std chg send £150 rcv classified as: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lixiran/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in log\n"
     ]
    }
   ],
   "source": [
    "listPosts,listClasses= X,y\n",
    "myVocabList=createVocabList(listPosts)\n",
    "trainMat=[]\n",
    "\n",
    "#for postinDoc in listPosts:\n",
    "trainMat.append(setOfWords2Vec(myVocabList,postinDoc))\n",
    "p0V,p1V,pAb=trainNB1(trainMat,listClasses)\n",
    "testEntry= X_train[5]\n",
    "thisDoc=setOfWords2Vec(myVocabList,testEntry)\n",
    "print(\" \".join(X_train[5]),'classified as:',classifyNB(thisDoc,p0V,p1V,pAb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions:\n",
    "#####  1. As a result, the Bayes classifier return a judgment, in which we can tell whether the email is spam or not.\n",
    "#####  2. I haven't find the solution of  running  the loop in order to print all the results and do the further cross-validation yet..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  NaiveBayes sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"SMSSpamCollection.csv\", names=['tag', 'text'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer() \n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split(r'\\s+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=data['text']\n",
    "y=data['tag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize text\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train)\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train)\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test)\n",
    "\n",
    "X_train_vect = pd.concat([pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "X_test_vect = pd.concat([pd.DataFrame(tfidf_test.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final evaluation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.551 / Recall: 0.901 / F1-Score: 0.684 / Accuracy: 0.886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(X_train_vect, y_train) \n",
    "clf_model = clf.fit(X_train_vect, y_train)\n",
    "y_pred = clf_model.predict(X_test_vect)\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print('Precision: {} / Recall: {} / F1-Score: {} / Accuracy: {}'.format(\n",
    "    round(precision, 3), round(recall, 3), round(fscore,3), round(acs(y_test,y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_label = [\"ham\", \"spam\"]\n",
    "df_cm = pd.DataFrame(cm, index=class_label, columns=class_label)\n",
    "sns.heatmap(df_cm, annot=True,cmap=plt.cm.Greens, fmt='d',annot_kws={'size':15}, linewidths=0.3)\n",
    "\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88043478, 0.89402174, 0.88586957, 0.88043478, 0.89918256])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5-fold validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf, X_test_vect, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "1. With sklearn Naive Bayes classifier, we can get the result easier as the algorithm has already been set up.\n",
    "2. The final results are moderate, with recision only 0.551, while Recall is 0.901 and Accuracy is 0.886. There are several Bayes models in sklearn, different models could bring different accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
